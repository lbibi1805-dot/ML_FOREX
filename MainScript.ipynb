{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 0: IMPORT LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  \n",
    "from sklearn.preprocessing import OneHotEncoder      \n",
    "from sklearn.model_selection import KFold   \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib \n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# Additional useful imports\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_absolute_error, median_absolute_error\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import os\n",
    "import yfinance as yf\n",
    "import ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 1: DEFINE FOREX PAIRS LIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "forex_pairs = ['EURUSD=X', 'USDJPY=X', 'GBPUSD=X', 'AUDUSD=X', 'NZDUSD=X', 'EURJPY=X'] # You can update by adding more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STEP 2: GET FOREX DATA CRAWLING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1: Define Reference List** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Forex_Data'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)      # Create directory if has not exist yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2: Crawl all FOREX data needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for EURUSD=X...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for EURUSD=X at Forex_Data\\EURUSD=X_data.csv\n",
      "\n",
      "Downloading data for USDJPY=X...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for USDJPY=X at Forex_Data\\USDJPY=X_data.csv\n",
      "\n",
      "Downloading data for GBPUSD=X...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for GBPUSD=X at Forex_Data\\GBPUSD=X_data.csv\n",
      "\n",
      "Downloading data for AUDUSD=X...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for AUDUSD=X at Forex_Data\\AUDUSD=X_data.csv\n",
      "\n",
      "Downloading data for NZDUSD=X...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for NZDUSD=X at Forex_Data\\NZDUSD=X_data.csv\n",
      "\n",
      "Downloading data for EURJPY=X...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data for EURJPY=X at Forex_Data\\EURJPY=X_data.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tải dữ liệu lịch sử cho mỗi mã Forex và lưu vào tệp CSV\n",
    "for pair in forex_pairs:\n",
    "    print(f\"Downloading data for {pair}...\")\n",
    "    data = yf.download(pair, period=\"max\", interval='1d')  # Dowload the data since the day it appears\n",
    "    data.reset_index(inplace=True)  # Reset index to ense Date is a normal column\n",
    "    \n",
    "    # Save the data to the CSV file\n",
    "    file_path = os.path.join(directory, f'{pair}_data.csv')\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Saved data for {pair} at {file_path}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3:  MERGE ALL FOREX DATA INTO ONE DATAFRAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  EURUSD=X_Close  USDJPY=X_Close  GBPUSD=X_Close  \\\n",
      "0     1996-10-30             NaN      114.180000             NaN   \n",
      "1     1996-11-01             NaN      113.500000             NaN   \n",
      "2     1996-11-04             NaN      113.879997             NaN   \n",
      "3     1996-11-05             NaN      114.250000             NaN   \n",
      "4     1996-11-06             NaN      113.949997             NaN   \n",
      "...          ...             ...             ...             ...   \n",
      "7253  2024-09-18        1.112310      142.014999        1.316742   \n",
      "7254  2024-09-19        1.111482      142.710007        1.320115   \n",
      "7255  2024-09-20             NaN             NaN        1.328180   \n",
      "7256  2024-09-21             NaN             NaN        1.331611   \n",
      "7257  2024-09-22             NaN             NaN             NaN   \n",
      "\n",
      "      AUDUSD=X_Close  NZDUSD=X_Close  EURJPY=X_Close  \n",
      "0                NaN             NaN             NaN  \n",
      "1                NaN             NaN             NaN  \n",
      "2                NaN             NaN             NaN  \n",
      "3                NaN             NaN             NaN  \n",
      "4                NaN             NaN             NaN  \n",
      "...              ...             ...             ...  \n",
      "7253        0.676270        0.619398      157.962006  \n",
      "7254        0.676370        0.620890      158.584000  \n",
      "7255        0.680958        0.623702             NaN  \n",
      "7256             NaN             NaN             NaN  \n",
      "7257        0.680874        0.623947             NaN  \n",
      "\n",
      "[7258 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo một DataFrame trống\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "for pair in forex_pairs:\n",
    "    file_path = os.path.join(directory, f'{pair}_data.csv')\n",
    "    \n",
    "    # Đọc dữ liệu từ file CSV\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Đổi tên cột 'Close' để phân biệt giữa các cặp tiền\n",
    "    data.rename(columns={'Close': f'{pair}_Close'}, inplace=True)\n",
    "    \n",
    "    # Chỉ lấy cột 'Date' và 'Close' để kết hợp\n",
    "    if merged_data.empty:\n",
    "        merged_data = data[['Date', f'{pair}_Close']]  # Lần đầu tiên, lấy cả 'Date' và 'Close'\n",
    "    else:\n",
    "        merged_data = pd.merge(merged_data, data[['Date', f'{pair}_Close']], on='Date', how='outer')  # Ghép dựa trên cột 'Date'\n",
    "\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   **STEP 3: PRE-PROCESSING DATA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1. Load historical Forex data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**:\n",
    "- **Date Format**: DD/MM/YY. (FOR 1 MINUTE INTERVAL: YYYY-MM-DD HH:MM:SS)\n",
    "- **Interval**: 1d = 1 day, 1m = 1 minutes (YAHOO FINANCE ONLY SUPPLY DATA FOR THE LAST **7 DAYS** OF 1 MINUTE INTERVAL DATA) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
